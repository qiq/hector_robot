- dodelat testy, pocitat s lokalnim web serverem (v Perlu)
- lokalni dns server (v Perlu) pouzit pro test dns a dns + perl
- test na webresource
- upravit resourceinfo, aby fungoval pro websiteresource
- nacitani a ukladani we websitemanager

- modul pro zpracovani robots.txt (wr + wsr, vypln ve wsr)

- upravit fetch a resolvedns, aby fungovaly s libovolnym resource
	- mozna jen resolvedns(?), fetch potrebuje primo modifikovatelny string

- items: jen korektne zpracovane resources, ne vsechny -- predelat
- jmena metod na velka pismena (krome getteru/setteru)

- webresource: pridat
	- pocet presmerovani (male cislo)
	- cil presmerovani

- website manager
	- nacitat a ukladat websiteresources
	- poustet dns resolution + robots.txt download
	- zpracovavat newlink
	- bude si ukladat websites v hash tabulce, paths v judy array/hash

- website resource
	- hostname: domenove jmeno 20 + 4 + 16 + 4 + hash + 4 + hash? + 32 lock
	- ip4addr: adresa
	- ip6addr: adresa
	- dnsExpire: kdy vyprsi preklad
	- paths: seznam path
		- name: cele jmeno (je v hash/judy array)
		- updatePeriod: jak casto obnovovat (kvantizovana hodnota, asi 4-255, bude to nejak v minutach 2^n)
			- upravuje se po kazdem stahnuti -- kdyz se zmena udala, tak se snizi, kdyz neudala, tak se o 1 zvysi
		- lastUpdate: kdy se obnovila stranka naposledy (4)
		- lastStatus: jestli byla stranka nalezena ci nikoliv (4)
		- cil presmerovani (optional)
	 - robotsLastUpdate: posledni obnova robots.txt
	 - deniedPaths: seznam zakazanych path (z robots.txt)

- ve zpracovani robots.txt je potreba nastaveni jmena, to bude parametr
- detekce opakujicich se retezcu v URL (staci jeden asi, neco jako /iso/test/iso)
	- to bude specialni filtr, zatim asi v perlu, co bude kontrolovat adresy

- query/response resource
	- getPathInfo: I: hostname, path; O: ip adresa, cksum, error
	- addPath: I: hostname, path; O: OK, already presend
	- pathChange: I: hostname, path, cksum; O: OK
	- list all sites: I: 0; out: [string]
	- list paths: I: hostname; out: [string]

Filter: rozdelit, presunout do hector_core, prepsat modify
filter: umet pracovat i s jednotlivou hlavickou (clear), umet filtrovat hlavicku (jakoze podle jmena, nechat jen specificke)
	* => keep()
- presunout filter do hector_core

- upravit filter: zmenit na filter + modify

- fetch -- poradny test, napr. pres localhost a apache na chroustalku.
- testy pro ruzne moduly
	- (Perl i C++)

- OTESTOVAT: resolver module v C++
  	http://www.catonmat.net/blog/asynchronous-dns-resolution#comments
	- bude pouzivat libunbound -- standardni operace, ale s pouzitim libev
	- vezme host, vrati IP adresu (plus do kdy je platna)
	- multi module
- OTESTOVAT: stahovaci modul
	v C++ pomoci curl (a libevent/libev)

- vyzkouset stahnout stranku

- reorder modul
- cistici modul

DONE
- dodelat websiteresource, aby pouzival jarray
- pridat detekci jarray do configure.ac
- filter: upravit, aby nevyzadoval WebResource
- resolver module (blokujici, v Perlu)
	- jen obyc prevede jmeno na IP adresu
- CreateWebResource: precist seznam URL a vygenerovat WebResources
	- bylo by pekne, aby slo pridavat URL i za chodu, jenze aby to
	  slo snadno, tak se to musi napsat v C++ (v Perlu to nejde,
	  kvuli zamcenemu objektu, kdyz dojdou URL, musi se modul uspat
	  -- a na to musi byt condition variable. Jenze do Perlu muze
	  jen jedno vlakno naraz.
- stahovaci modul (v Perlu), parametry se jeste uvidi
- url parsing module
	- dostane URL, udela z nej komponenty (pomoci google-url knihovny)
	- ty preda dal
